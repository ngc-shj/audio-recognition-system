# ========================================
# Audio Recognition System Configuration
# ========================================

# モデル設定
models:
  # 音声認識モデル (Whisper)
  asr:
    darwin:  # macOS
      model_path: "mlx-community/whisper-large-v3-turbo"
      model_size: "large-v3-turbo"
    default:  # Linux/Windows
      model_path: null  # Whisperの自動ダウンロード
      model_size: "large-v3-turbo"
  
  # 翻訳モデル (LLM)
  translation:
    darwin:  # macOS
      model_path: "mlx-community/gpt-oss-20b-MXFP4-Q4" # MLX対応モデル
      #model_path: "mlx-community/llm-jp-3-3.7b-instruct"
    default:  # Linux/Windows
      model_path: "openai/gpt-oss-20b" # Hugging Faceリポジトリまたはローカルパス

    # セキュリティ設定：trust_remote_code の有効化
    # デフォルトは false (安全性を優先)
    # カスタムコードを含むモデルを使用する場合は true に設定してください
    trust_remote_code: false

    # API Server設定 (LM Studio, Ollama, vLLM等のOpenAI互換API)
    # api.enabledがtrueの場合、ローカルモデルロードではなくAPIサーバーを使用
    api:
      enabled: true  # trueに設定するとAPIサーバーを使用
      #base_url: "http://localhost:1234/v1"  # APIサーバーのベースURL (LM Studioデフォルト)
      base_url: "http://192.168.11.18:1234/v1"  # APIサーバーのベースURL (LM Studioデフォルト)
      api_key: ""  # API Key (不要な場合は空文字列)
      model: "local-model"  # 使用するモデル名 (サーバー側で設定したモデル名)
      timeout: 60  # タイムアウト時間（秒）
      max_retries: 3  # リトライ回数

    # GGUF形式のモデル対応 (Linux/Windows)
    gguf:
      enabled: false  # trueに設定するとGGUFモデルを使用
      model_path: "unsloth/gpt-oss-20b-GGUF"  # Hugging Faceリポジトリまたはローカルパス
      model_file: "gpt-oss-20b-Q4_K_M.gguf"  # モデルファイル名
      n_ctx: 4096  # コンテキストウィンドウサイズ
      n_gpu_layers: -1  # GPU使用レイヤー数 (-1で全レイヤー)
      n_threads: 8  # CPU使用スレッド数

    # モデル再読み込み設定
    reload:
      interval_seconds: 7200  # 120分 (2時間)
      interval_seconds_darwin: 7200  # macOS: 120分（2時間）
    
    # エラーハンドリング
    error_handling:
      max_consecutive_errors: 1
      error_cooldown_seconds: 2
      retry_failed_translations: true

# 音声入力設定
audio:
  format: "int16"  # int8, int16, int32, float32
  sample_rate: 16000
  channels: 1
  chunk_size: 1024
  buffer_duration: 5.0  # 秒（非推奨：動的バッファが有効な場合は無視されます）

  # 音声検出設定
  voice_detection:
    silence_threshold: 0.005
    voice_activity_threshold: 0.01
    silence_duration: 1.0  # 秒（非推奨：動的バッファが有効な場合は無視されます）
    zero_crossing_rate_threshold: 0.1  # ゼロ交差率しきい値（VAD改善用）

  # 動的バッファ設定（より適切な文章区切りのため）
  dynamic_buffer:
    min_duration: 2.0  # 秒: 最小バッファ長
    max_duration: 30.0  # 秒: 最大バッファ長（強制区切り）
    short_pause: 0.3  # 秒: 短いポーズ（文中の間）
    medium_pause: 0.8  # 秒: 中ポーズ（文の区切り）
    long_pause: 1.5  # 秒: 長いポーズ（発話終了）

  # 入力デバイス (nullで自動検出)
  input_device: null

# 言語設定
language:
  source: "en"  # 音声認識の入力言語
  target: "ja"  # 翻訳の出力言語

# 翻訳設定
translation:
  enabled: true
  batch_size: 5
  
  # コンテキスト管理
  context:
    window_size: 8  # 保持する過去の文脈数
    separator: "\n"
  
  # 生成パラメータ
  generation:
    darwin:
      max_tokens: 4096
      temperature: 0.8
      top_p: 1.0
      top_k: 0
      repetition_penalty: 1.1
      repetition_context_size: 20
    default:
      max_new_tokens: 4096
      temperature: 0.8
      top_p: 1.0
      top_k: 0
      repetition_penalty: 1.1
      do_sample: true

# 出力設定
output:
  directory: "logs"
  
  # ログファイル設定
  logging:
    recognized_audio: true
    translated_text: true
    bilingual_log: true
  
  # ファイル名フォーマット
  filename_format:
    timestamp: "%Y%m%d_%H%M%S"
    recognized: "recognized_audio_log_{lang}_{timestamp}.txt"
    translated: "translated_text_log_{source}-{target}_{timestamp}.txt"
    bilingual: "bilingual_translation_log_{source}-{target}_{timestamp}.txt"

# システムリソース設定
resources:
  threads:
    min: 2
    max: 8
  
# デバッグ設定
debug:
  enabled: false
  save_audio_samples: false
  verbose_logging: false
  print_model_info: false

# プロファイル設定 (環境別)
profiles:
  development:
    debug:
      enabled: true
      verbose_logging: true
    models:
      asr:
        darwin:
          model_size: "base"  # 高速化
      translation:
        darwin:
          model_path: "mlx-community/Llama-3.2-3B-Instruct-4bit"  # 軽量モデル
    translation:
      batch_size: 2
  
  production:
    debug:
      enabled: false
    models:
      asr:
        darwin:
          model_size: "large-v3-turbo"
    output:
      logging:
        recognized_audio: true
        translated_text: true
        bilingual_log: true
  
  testing:
    debug:
      enabled: true
      save_audio_samples: true
    audio:
      buffer_duration: 2.0
    translation:
      batch_size: 1
